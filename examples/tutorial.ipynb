{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828c6387",
   "metadata": {},
   "source": [
    "# pyKOSMOS++: AI-Assisted Spectroscopic Reduction Tutorial\n",
    "\n",
    "**Author:** Gourav Khullar  \n",
    "**Version:** 0.1.0  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "**pyKOSMOS++** is an AI-assisted spectroscopic reduction pipeline designed for APO-KOSMOS longslit observations. This project combines traditional astronomical data reduction techniques with modern large language model (LLM) assistance to streamline the workflow from raw CCD images to science-ready, wavelength-calibrated 1D spectra.\n",
    "\n",
    "### Built Upon pyKOSMOS\n",
    "\n",
    "This pipeline is built upon the foundation of [**pyKOSMOS**](https://github.com/jradavenport/pykosmos) by **James R. A. Davenport** (University of Washington), with key contributions from **Francisca Chabour Barra** (University of Washington), Azalee Bostroem, and Erin Howard. The reference data used in this tutorial (arc lamp linelists, extinction curves, standard star catalogs) comes from the pyKOSMOS resource directory.\n",
    "\n",
    "**Citations:**\n",
    "- Davenport, J. R. A. et al. (2023). *pyKOSMOS: Longslit Spectroscopy Reduction*. DOI:10.5281/zenodo.10152905\n",
    "- Davenport, J. R. A. (2016). *PyDIS: Python Spectroscopy Reduction Suite*. Zenodo\n",
    "\n",
    "### Project Ethos\n",
    "\n",
    "This pipeline embodies three core principles:\n",
    "\n",
    "1. **Accessibility First**: Reduce the barrier to entry for spectroscopic data analysis by providing automated, push-button reduction with sensible defaults while maintaining full customizability for expert users.\n",
    "\n",
    "2. **Transparency & Education**: Every reduction step is documented, validated, and visualized. Users understand not just *what* the pipeline does, but *why* and *how*, with diagnostic plots and quality metrics at every stage.\n",
    "\n",
    "3. **AI-Augmented Development**: Built using AI assistance throughout the development process, demonstrating how LLMs can accelerate scientific software creation while maintaining rigor through comprehensive testing, validation, and adherence to established astronomical standards.\n",
    "\n",
    "### What This Notebook Does\n",
    "\n",
    "This tutorial demonstrates the complete spectroscopic reduction workflow:\n",
    "\n",
    "- **Calibration Creation** (Section 3): Combine bias and flat frames with sigma-clipped median stacking, validate against physics-based quality criteria\n",
    "- **Wavelength Calibration** (Section 4): Detect arc emission lines, match to catalog wavelengths (from pyKOSMOS linelists), fit Chebyshev polynomial solutions with BIC order selection (target RMS <0.2Ã…)\n",
    "- **Trace Detection** (Section 5): Identify spectral traces using cross-correlation with Gaussian templates (SNR â‰¥3Ïƒ threshold)\n",
    "- **Optimal Extraction** (Section 5): Extract 1D spectra using variance-weighted Horne (1986) algorithm with cosmic ray rejection\n",
    "- **Quality Assessment** (Section 6): Compute signal-to-noise ratio, wavelength accuracy, profile consistency, and assign quality grades\n",
    "- **Advanced Configuration** (Section 7): Customize parameters for faint sources, problematic wavelength solutions, or specific observing conditions\n",
    "- **Batch Processing** (Section 8): Automate reduction of entire observing runs with summary statistics\n",
    "\n",
    "### Expected Outcomes\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "âœ… Understand each step of the KOSMOS spectroscopic reduction workflow  \n",
    "âœ… Be able to process your own KOSMOS observations  \n",
    "âœ… Interpret quality metrics and diagnostic plots  \n",
    "âœ… Troubleshoot common reduction issues  \n",
    "âœ… Customize parameters for your specific science case  \n",
    "\n",
    "**Prerequisites:** Python â‰¥3.10, pyKOSMOS++ installed, KOSMOS FITS data organized in subdirectories\n",
    "\n",
    "**Estimated Time:** 15-20 minutes (interactive execution)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f764a0",
   "metadata": {},
   "source": [
    "## 1. Introduction & Setup\n",
    "\n",
    "First, let's import the necessary libraries and verify the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c21a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful!\n",
      "NumPy version: 2.0.0\n",
      "Matplotlib backend: inline\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Astronomy packages\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "from specutils import Spectrum1D\n",
    "\n",
    "# pyKOSMOS++ pipeline\n",
    "from pykosmospp.pipeline import PipelineRunner\n",
    "from pykosmospp.models import BiasFrame, FlatFrame, ArcFrame, ScienceFrame\n",
    "from pykosmospp.io.config import PipelineConfig\n",
    "from pykosmospp.calibration.combine import create_master_bias, create_master_flat\n",
    "from pykosmospp.wavelength.identify import detect_arc_lines\n",
    "from pykosmospp.wavelength.fit import fit_wavelength_solution\n",
    "from pykosmospp.extraction.trace import detect_traces_cross_correlation\n",
    "from pykosmospp.quality.metrics import compute_quality_metrics\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ“ All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Matplotlib backend: {plt.get_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34af6a5",
   "metadata": {},
   "source": [
    "### Load Configuration\n",
    "\n",
    "Load the default KOSMOS detector configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d10163",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelineConfig' object has no attribute 'detector'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m config_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../config/kosmos_defaults.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m PipelineConfig\u001b[38;5;241m.\u001b[39mfrom_yaml(config_path)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelineConfig' object has no attribute 'detector'"
     ]
    }
   ],
   "source": [
    "# Load default configuration\n",
    "config_path = Path('../config/kosmos_defaults.yaml')\n",
    "config = PipelineConfig.from_yaml(config_path)\n",
    "\n",
    "print(\"KOSMOS Detector Specifications:\")\n",
    "print(f\"  Gain: {config['detector']['gain']} e-/ADU\")\n",
    "print(f\"  Read Noise: {config['detector']['readnoise']} e-\")\n",
    "print(f\"  Saturation: {config['detector']['saturate']} ADU\")\n",
    "print(f\"\\nWavelength Calibration:\")\n",
    "print(f\"  Max polynomial order: {config['wavelength']['max_order']}\")\n",
    "print(f\"  Initial dispersion: {config['wavelength']['initial_dispersion']} Ã…/pixel\")\n",
    "print(f\"\\nTrace Detection:\")\n",
    "print(f\"  Expected FWHM: {config['trace_detection']['expected_fwhm']} pixels\")\n",
    "print(f\"  Min SNR: {config['trace_detection']['min_snr']}\")\n",
    "print(f\"  Sky buffer: {config['extraction']['sky_buffer']} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c78dd6",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Let's examine the structure of KOSMOS FITS files and understand the data organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27308fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data directory (adjust path to your data location)\n",
    "data_dir = Path('data/2024-01-15/galaxy_NGC1234')\n",
    "\n",
    "# Or use example data if available\n",
    "if not data_dir.exists():\n",
    "    data_dir = Path('examples/data')\n",
    "    print(f\"Using example data from: {data_dir}\")\n",
    "\n",
    "# Check directory structure\n",
    "for subdir in ['biases', 'flats', 'arcs', 'science']:\n",
    "    path = data_dir / subdir\n",
    "    if path.exists():\n",
    "        n_files = len(list(path.glob('*.fits')))\n",
    "        print(f\"âœ“ {subdir}: {n_files} FITS files\")\n",
    "    else:\n",
    "        print(f\"âœ— {subdir}: directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8563fd85",
   "metadata": {},
   "source": [
    "### Inspect FITS Headers\n",
    "\n",
    "Examine the header keywords used for frame classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample bias frame\n",
    "bias_files = list((data_dir / 'biases').glob('*.fits'))\n",
    "if bias_files:\n",
    "    with fits.open(bias_files[0]) as hdul:\n",
    "        header = hdul[0].header\n",
    "        print(\"Sample Bias Frame Header:\")\n",
    "        print(f\"  IMAGETYP: {header.get('IMAGETYP', 'N/A')}\")\n",
    "        print(f\"  OBJECT: {header.get('OBJECT', 'N/A')}\")\n",
    "        print(f\"  EXPTIME: {header.get('EXPTIME', 'N/A')} seconds\")\n",
    "        print(f\"  DATE-OBS: {header.get('DATE-OBS', 'N/A')}\")\n",
    "        print(f\"  NAXIS1: {header.get('NAXIS1', 'N/A')} (spectral)\")\n",
    "        print(f\"  NAXIS2: {header.get('NAXIS2', 'N/A')} (spatial)\")\n",
    "else:\n",
    "    print(\"No bias files found. Please ensure data directory contains FITS files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0941422",
   "metadata": {},
   "source": [
    "### Visualize Raw Frames\n",
    "\n",
    "Display examples of each frame type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfe4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "frame_types = [\n",
    "    ('biases', 'Bias Frame', 'gray'),\n",
    "    ('flats', 'Flat Field', 'viridis'),\n",
    "    ('arcs', 'Arc Lamp', 'plasma'),\n",
    "    ('science', 'Science Frame', 'viridis')\n",
    "]\n",
    "\n",
    "for ax, (subdir, title, cmap) in zip(axes.flat, frame_types):\n",
    "    files = list((data_dir / subdir).glob('*.fits'))\n",
    "    if files:\n",
    "        with fits.open(files[0]) as hdul:\n",
    "            data = hdul[0].data\n",
    "            im = ax.imshow(data, cmap=cmap, origin='lower', \n",
    "                          vmin=np.percentile(data, 1), \n",
    "                          vmax=np.percentile(data, 99))\n",
    "            ax.set_title(title)\n",
    "            ax.set_xlabel('Spectral Direction (pixels)')\n",
    "            ax.set_ylabel('Spatial Direction (pixels)')\n",
    "            plt.colorbar(im, ax=ax, label='ADU')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No {subdir} found', \n",
    "               ha='center', va='center', transform=ax.transAxes)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12978a02",
   "metadata": {},
   "source": [
    "## 3. Calibration Creation\n",
    "\n",
    "Create master bias and flat frames using sigma-clipped median combination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e049b",
   "metadata": {},
   "source": [
    "### Master Bias\n",
    "\n",
    "Combine multiple bias frames to create a master bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff45a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: VerifyWarning: Verification reported errors: [astropy.io.fits.verify]\n",
      "WARNING: VerifyWarning: Card 'CD1_1' is not FITS standard (invalid value string: '+NAN                 / WCS (1/InstScaleX)*cos(InstAng)').  Fixed 'CD1_1' card to meet the FITS standard. [astropy.io.fits.verify]\n",
      "WARNING: VerifyWarning: Note: astropy.io.fits uses zero-based indexing.\n",
      " [astropy.io.fits.verify]\n",
      "WARNING: VerifyWarning: Card 'CD1_2' is not FITS standard (invalid value string: '+NAN                 / WCS (1/InstScaleY)*sin(InstAng)').  Fixed 'CD1_2' card to meet the FITS standard. [astropy.io.fits.verify]\n",
      "WARNING: VerifyWarning: Card 'CD2_1' is not FITS standard (invalid value string: '+NAN                 / WCS (-1/(InstScaleX)*sin(InstAng)').  Fixed 'CD2_1' card to meet the FITS standard. [astropy.io.fits.verify]\n",
      "WARNING: VerifyWarning: Card 'CD2_2' is not FITS standard (invalid value string: '+NAN                 / WCS (1/InstScaleY)*cos(InstAng)').  Fixed 'CD2_2' card to meet the FITS standard. [astropy.io.fits.verify]\n",
      "WARNING: FITSFixedWarning: RADECSYS= 'Mount' / Coordinate system, per TCC ObjSys \n",
      "the RADECSYS keyword is deprecated, use RADESYSa. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: CD1_1 = '+NAN ' / WCS (1/InstScaleX)*cos(InstAng) \n",
      "a floating-point value was expected. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: CD1_2 = '+NAN ' / WCS (1/InstScaleY)*sin(InstAng) \n",
      "a floating-point value was expected. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: CD2_1 = '+NAN ' / WCS (-1/(InstScaleX)*sin(InstAng) \n",
      "a floating-point value was expected. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: CD2_2 = '+NAN ' / WCS (1/InstScaleY)*cos(InstAng) \n",
      "a floating-point value was expected. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 60707.020265 from DATE-OBS'. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 60707.019630 from DATE-OBS'. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 60707.021538 from DATE-OBS'. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 60707.025263 from DATE-OBS'. [astropy.wcs.wcs]\n",
      "WARNING: FITSFixedWarning: 'datfix' made the change 'Set MJD-OBS to 60707.024624 from DATE-OBS'. [astropy.wcs.wcs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 bias frames\n",
      "INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n",
      "INFO: overwriting NDData's current unit with specified unit. [astropy.nddata.nddata]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MasterBias.__init__() got an unexpected keyword argument 'source_frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(bias_frames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bias frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create master bias\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m master_bias \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_master_bias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_frames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMaster Bias Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Median level: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmaster_bias\u001b[38;5;241m.\u001b[39mbias_level\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ADU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/projects/UWashington/apo/reductions/pykosmos_spec_ai/src/calibration/combine.py:95\u001b[0m, in \u001b[0;36mcreate_master_bias\u001b[0;34m(bias_frames, method)\u001b[0m\n\u001b[1;32m     92\u001b[0m combined \u001b[38;5;241m=\u001b[39m sigma_clipped_median_combine(ccd_list)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Create MasterBias\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m master_bias \u001b[38;5;241m=\u001b[39m \u001b[43mMasterBias\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcombined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombination_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m master_bias\n",
      "\u001b[0;31mTypeError\u001b[0m: MasterBias.__init__() got an unexpected keyword argument 'source_frames'"
     ]
    }
   ],
   "source": [
    "# Load bias frames\n",
    "bias_files = list((data_dir / 'biases').glob('*.fits'))\n",
    "bias_frames = [BiasFrame.from_fits(f) for f in bias_files[:5]]\n",
    "\n",
    "print(f\"Loaded {len(bias_frames)} bias frames\")\n",
    "\n",
    "# Create master bias\n",
    "master_bias = create_master_bias(bias_frames, method='median')\n",
    "\n",
    "print(f\"\\nMaster Bias Statistics:\")\n",
    "print(f\"  Median level: {master_bias.bias_level:.2f} ADU\")\n",
    "print(f\"  Std deviation: {master_bias.bias_stdev:.2f} ADU\")\n",
    "print(f\"  Frames combined: {master_bias.n_combined}\")\n",
    "\n",
    "# Visualize master bias\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "im1 = ax1.imshow(master_bias.data.data, cmap='gray', origin='lower')\n",
    "ax1.set_title('Master Bias')\n",
    "ax1.set_xlabel('Spectral Direction')\n",
    "ax1.set_ylabel('Spatial Direction')\n",
    "plt.colorbar(im1, ax=ax1, label='ADU')\n",
    "\n",
    "# Histogram of bias levels\n",
    "ax2.hist(master_bias.data.data.flatten(), bins=50, alpha=0.7)\n",
    "ax2.axvline(master_bias.bias_level, color='r', linestyle='--', \n",
    "           label=f'Median: {master_bias.bias_level:.1f} ADU')\n",
    "ax2.set_xlabel('ADU')\n",
    "ax2.set_ylabel('Pixel Count')\n",
    "ax2.set_title('Bias Level Distribution')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff4f8e",
   "metadata": {},
   "source": [
    "### Master Flat\n",
    "\n",
    "Create a normalized flat field from bias-corrected flats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load flat frames\n",
    "flat_files = list((data_dir / 'flats').glob('*.fits'))\n",
    "flat_frames = [FlatFrame.from_fits(f) for f in flat_files[:3]]\n",
    "\n",
    "print(f\"Loaded {len(flat_frames)} flat frames\")\n",
    "\n",
    "# Create master flat\n",
    "master_flat = create_master_flat(flat_frames, master_bias, method='median')\n",
    "\n",
    "print(f\"\\nMaster Flat Statistics:\")\n",
    "print(f\"  Normalization region: {master_flat.normalization_region}\")\n",
    "print(f\"  Bad pixel fraction: {master_flat.bad_pixel_fraction:.4f}\")\n",
    "print(f\"  Frames combined: {master_flat.n_combined}\")\n",
    "\n",
    "# Visualize master flat\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "im1 = ax1.imshow(master_flat.data.data, cmap='viridis', origin='lower',\n",
    "                vmin=0.8, vmax=1.2)\n",
    "ax1.set_title('Master Flat (Normalized)')\n",
    "ax1.set_xlabel('Spectral Direction')\n",
    "ax1.set_ylabel('Spatial Direction')\n",
    "plt.colorbar(im1, ax=ax1, label='Normalized Response')\n",
    "\n",
    "# Cross-dispersion profile\n",
    "spatial_profile = np.median(master_flat.data.data, axis=1)\n",
    "ax2.plot(spatial_profile)\n",
    "ax2.axhline(1.0, color='r', linestyle='--', label='Perfect Normalization')\n",
    "ax2.set_xlabel('Spatial Position (pixels)')\n",
    "ax2.set_ylabel('Normalized Response')\n",
    "ax2.set_title('Spatial Illumination Profile')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eb0f25",
   "metadata": {},
   "source": [
    "### Validate Calibrations\n",
    "\n",
    "Check calibration quality against physics-based criteria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykosmospp.quality.validate import validate_calibrations\n",
    "\n",
    "# Validate calibrations\n",
    "validation_result = validate_calibrations(master_bias, master_flat)\n",
    "\n",
    "print(\"Calibration Validation Results:\")\n",
    "print(f\"  Status: {'âœ“ PASS' if validation_result else 'âœ— FAIL'}\")\n",
    "if validation_result:\n",
    "    print(\"  All calibration quality checks passed:\")\n",
    "    print(f\"    â€¢ Bias variation < 10 ADU\")\n",
    "    print(f\"    â€¢ Flat normalization in valid range (0.5-1.5)\")\n",
    "    print(f\"    â€¢ Saturation fraction < 1%\")\n",
    "    print(f\"    â€¢ Bad pixel fraction < 5%\")\n",
    "else:\n",
    "    print(\"  WARNING: Some calibration checks failed.\")\n",
    "    print(\"  Review bias and flat statistics above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f3968",
   "metadata": {},
   "source": [
    "## 4. Wavelength Calibration\n",
    "\n",
    "Detect arc emission lines and fit a wavelength solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36bcde",
   "metadata": {},
   "source": [
    "### Detect Arc Lines\n",
    "\n",
    "Identify emission lines in arc lamp spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arc frame\n",
    "arc_files = list((data_dir / 'arcs').glob('*.fits'))\n",
    "if arc_files:\n",
    "    arc_frame = ArcFrame.from_fits(arc_files[0])\n",
    "    \n",
    "    # Extract 1D arc spectrum (median collapse)\n",
    "    arc_spectrum_1d = np.median(arc_frame.data.data, axis=0)\n",
    "    \n",
    "    # Detect lines\n",
    "    detected_lines = detect_arc_lines(\n",
    "        arc_spectrum_1d,\n",
    "        detection_threshold=5.0,\n",
    "        min_separation=5\n",
    "    )\n",
    "    \n",
    "    print(f\"Detected {len(detected_lines)} arc lines\")\n",
    "    print(f\"\\nSample detected lines (first 5):\")\n",
    "    for i, line in enumerate(detected_lines[:5]):\n",
    "        print(f\"  Line {i+1}: pixel {line['pixel']:.2f}, intensity {line['intensity']:.1f}\")\n",
    "    \n",
    "    # Visualize arc spectrum with detected lines\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    pixels = np.arange(len(arc_spectrum_1d))\n",
    "    ax.plot(pixels, arc_spectrum_1d, 'k-', linewidth=0.5, label='Arc Spectrum')\n",
    "    \n",
    "    # Mark detected lines\n",
    "    for line in detected_lines:\n",
    "        ax.axvline(line['pixel'], color='r', alpha=0.3, linewidth=1)\n",
    "    \n",
    "    ax.set_xlabel('Pixel')\n",
    "    ax.set_ylabel('Intensity (ADU)')\n",
    "    ax.set_title(f'Arc Lamp Spectrum ({len(detected_lines)} lines detected)')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No arc files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c028b03",
   "metadata": {},
   "source": [
    "### Fit Wavelength Solution\n",
    "\n",
    "Match detected lines to catalog and fit Chebyshev polynomial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykosmospp.wavelength.match import match_lines_to_catalog\n",
    "\n",
    "# Match lines to catalog (assuming He-Ne-Ar)\n",
    "matched_lines = match_lines_to_catalog(\n",
    "    detected_lines,\n",
    "    linelist_file='resources/pykosmos_reference/linelists/apohenear.dat',\n",
    "    initial_dispersion=1.0,  # Ã…/pixel\n",
    "    wavelength_range=(4000, 7000),  # Ã…\n",
    "    match_tolerance=2.0  # Ã…\n",
    ")\n",
    "\n",
    "print(f\"Matched {len(matched_lines)} lines to catalog\")\n",
    "\n",
    "if len(matched_lines) >= 10:\n",
    "    # Fit wavelength solution with BIC order selection\n",
    "    wavelength_solution = fit_wavelength_solution(\n",
    "        matched_lines,\n",
    "        order_range=(3, 7),\n",
    "        sigma_clip=3.0,\n",
    "        max_iterations=5\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nWavelength Solution:\")\n",
    "    print(f\"  Polynomial order: {wavelength_solution.order}\")\n",
    "    print(f\"  RMS residual: {wavelength_solution.rms_residual:.4f} Ã…\")\n",
    "    print(f\"  Lines used: {wavelength_solution.n_lines_identified}\")\n",
    "    print(f\"  Wavelength range: {wavelength_solution.wavelength_range[0]:.1f} - {wavelength_solution.wavelength_range[1]:.1f} Ã…\")\n",
    "    \n",
    "    # Plot wavelength fit and residuals\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "    \n",
    "    # Wavelength vs pixel with fit\n",
    "    pixels = np.array([line['pixel'] for line in matched_lines])\n",
    "    wavelengths = np.array([line['wavelength'] for line in matched_lines])\n",
    "    pixel_grid = np.linspace(0, len(arc_spectrum_1d), 1000)\n",
    "    wavelength_grid = wavelength_solution.wavelength(pixel_grid)\n",
    "    \n",
    "    ax1.plot(pixels, wavelengths, 'ro', label='Identified Lines')\n",
    "    ax1.plot(pixel_grid, wavelength_grid, 'b-', linewidth=2, label=f'Fit (order {wavelength_solution.order})')\n",
    "    ax1.set_ylabel('Wavelength (Ã…)')\n",
    "    ax1.set_title('Wavelength Solution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals\n",
    "    fitted_wavelengths = wavelength_solution.wavelength(pixels)\n",
    "    residuals = wavelengths - fitted_wavelengths\n",
    "    \n",
    "    ax2.plot(pixels, residuals, 'ro')\n",
    "    ax2.axhline(0, color='b', linestyle='-', linewidth=2)\n",
    "    ax2.axhline(wavelength_solution.rms_residual, color='r', linestyle='--', \n",
    "               label=f'RMS = {wavelength_solution.rms_residual:.4f} Ã…')\n",
    "    ax2.axhline(-wavelength_solution.rms_residual, color='r', linestyle='--')\n",
    "    ax2.set_xlabel('Pixel')\n",
    "    ax2.set_ylabel('Residual (Ã…)')\n",
    "    ax2.set_title('Wavelength Fit Residuals')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient line matches for wavelength solution fitting.\")\n",
    "    print(\"Need â‰¥10 matched lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66b359",
   "metadata": {},
   "source": [
    "## 5. Trace Detection & Extraction\n",
    "\n",
    "Identify spectral traces and extract 1D spectra using optimal extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b8ed6b",
   "metadata": {},
   "source": [
    "### Detect Traces via Cross-Correlation\n",
    "\n",
    "Find spectral traces using cross-correlation with Gaussian templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load science frame\n",
    "science_files = list((data_dir / 'science').glob('*.fits'))\n",
    "if science_files:\n",
    "    science_frame = ScienceFrame.from_fits(science_files[0])\n",
    "    \n",
    "    # Apply calibrations\n",
    "    calibrated_data = (science_frame.data.data - master_bias.data.data) / master_flat.data.data\n",
    "    \n",
    "    # Detect traces\n",
    "    traces = detect_traces_cross_correlation(\n",
    "        calibrated_data,\n",
    "        expected_fwhm=4.0,\n",
    "        min_snr=3.0,\n",
    "        min_separation=20\n",
    "    )\n",
    "    \n",
    "    print(f\"Detected {len(traces)} trace(s)\")\n",
    "    for i, trace in enumerate(traces):\n",
    "        print(f\"\\nTrace {i+1}:\")\n",
    "        print(f\"  Center position: {np.median(trace.spatial_positions):.1f} pixels\")\n",
    "        print(f\"  SNR estimate: {trace.snr_estimate:.2f}\")\n",
    "        print(f\"  Spatial extent: {len(trace.spatial_positions)} pixels\")\n",
    "    \n",
    "    # Visualize 2D spectrum with detected traces\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    im = ax.imshow(calibrated_data, cmap='viridis', origin='lower',\n",
    "                  vmin=np.percentile(calibrated_data, 1),\n",
    "                  vmax=np.percentile(calibrated_data, 99),\n",
    "                  aspect='auto')\n",
    "    \n",
    "    # Overlay traces\n",
    "    for i, trace in enumerate(traces):\n",
    "        ax.plot(trace.spectral_pixels, trace.spatial_positions, \n",
    "               'r-', linewidth=2, label=f'Trace {i+1}')\n",
    "    \n",
    "    ax.set_xlabel('Spectral Direction (pixels)')\n",
    "    ax.set_ylabel('Spatial Direction (pixels)')\n",
    "    ax.set_title(f'Calibrated 2D Spectrum ({len(traces)} trace(s) detected)')\n",
    "    ax.legend()\n",
    "    plt.colorbar(im, ax=ax, label='Calibrated Flux')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No science files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c4f10",
   "metadata": {},
   "source": [
    "### Extract 1D Spectrum\n",
    "\n",
    "Perform optimal extraction using spatial profile weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykosmospp.extraction.extract import extract_optimal\n",
    "from pykosmospp.extraction.sky import estimate_sky_background\n",
    "\n",
    "if traces:\n",
    "    # Focus on first trace\n",
    "    trace = traces[0]\n",
    "    \n",
    "    # Estimate and subtract sky background\n",
    "    sky_2d = estimate_sky_background(\n",
    "        calibrated_data,\n",
    "        trace,\n",
    "        sky_buffer=30,\n",
    "        sigma_clip=3.0\n",
    "    )\n",
    "    \n",
    "    sky_subtracted = calibrated_data - sky_2d\n",
    "    \n",
    "    # Extract 1D spectrum\n",
    "    spectrum_1d = extract_optimal(\n",
    "        sky_subtracted,\n",
    "        trace,\n",
    "        aperture_width=10\n",
    "    )\n",
    "    \n",
    "    # Apply wavelength calibration\n",
    "    wavelengths = wavelength_solution.wavelength(trace.spectral_pixels)\n",
    "    \n",
    "    print(\"Extraction complete!\")\n",
    "    print(f\"  Spectral length: {len(spectrum_1d.flux)} pixels\")\n",
    "    print(f\"  Wavelength range: {wavelengths[0]:.1f} - {wavelengths[-1]:.1f} Ã…\")\n",
    "    print(f\"  Median flux: {np.median(spectrum_1d.flux.value):.2f}\")\n",
    "    \n",
    "    # Plot extracted 1D spectrum\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Sky-subtracted 2D spectrum\n",
    "    ax1.imshow(sky_subtracted, cmap='viridis', origin='lower',\n",
    "              vmin=np.percentile(sky_subtracted, 1),\n",
    "              vmax=np.percentile(sky_subtracted, 99),\n",
    "              aspect='auto')\n",
    "    ax1.plot(trace.spectral_pixels, trace.spatial_positions, 'r-', linewidth=2)\n",
    "    ax1.set_ylabel('Spatial (pixels)')\n",
    "    ax1.set_title('Sky-Subtracted 2D Spectrum')\n",
    "    \n",
    "    # 1D extracted spectrum\n",
    "    ax2.plot(wavelengths, spectrum_1d.flux.value, 'k-', linewidth=0.5)\n",
    "    ax2.set_xlabel('Wavelength (Ã…)')\n",
    "    ax2.set_ylabel('Flux')\n",
    "    ax2.set_title('Extracted 1D Spectrum (Wavelength Calibrated)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18dda8",
   "metadata": {},
   "source": [
    "## 6. Quality Assessment\n",
    "\n",
    "Compute quality metrics and assign overall grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2deca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute quality metrics\n",
    "metrics = compute_quality_metrics(spectrum_1d)\n",
    "\n",
    "print(\"Quality Metrics:\")\n",
    "print(f\"  Median SNR: {metrics['median_snr']:.2f}\")\n",
    "if 'wavelength_rms' in metrics:\n",
    "    print(f\"  Wavelength RMS: {metrics['wavelength_rms']:.4f} Ã…\")\n",
    "if 'profile_consistency_score' in metrics:\n",
    "    print(f\"  Profile consistency: {metrics['profile_consistency_score']:.3f}\")\n",
    "print(f\"  Overall grade: {metrics['overall_grade']}\")\n",
    "\n",
    "# Interpret grade\n",
    "grade_interpretation = {\n",
    "    'Excellent': 'High SNR (>20), excellent wavelength calibration (RMS<0.1Ã…)',\n",
    "    'Good': 'Good SNR (10-20), good wavelength calibration (RMS<0.2Ã…)',\n",
    "    'Fair': 'Fair SNR (5-10), acceptable wavelength calibration (RMS<0.3Ã…)',\n",
    "    'Poor': 'Low SNR (<5) or poor wavelength calibration (RMS>0.3Ã…)'\n",
    "}\n",
    "\n",
    "grade = metrics['overall_grade']\n",
    "print(f\"\\nGrade Interpretation:\")\n",
    "print(f\"  {grade}: {grade_interpretation[grade]}\")\n",
    "\n",
    "if grade in ['Excellent', 'Good']:\n",
    "    print(\"\\nâœ“ Spectrum meets quality requirements for scientific analysis.\")\n",
    "elif grade == 'Fair':\n",
    "    print(\"\\nâš  Spectrum has acceptable quality but may benefit from:\")\n",
    "    print(\"  â€¢ Longer integration time for higher SNR\")\n",
    "    print(\"  â€¢ Better arc lamp exposure for wavelength calibration\")\n",
    "else:\n",
    "    print(\"\\nâœ— Spectrum quality is poor. Consider:\")\n",
    "    print(\"  â€¢ Significantly longer integration time\")\n",
    "    print(\"  â€¢ Reviewing observing conditions\")\n",
    "    print(\"  â€¢ Checking calibration quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff475a0",
   "metadata": {},
   "source": [
    "## 7. Advanced Parameters\n",
    "\n",
    "Customize reduction parameters for specific observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa93ffa",
   "metadata": {},
   "source": [
    "### Adjust Trace Detection Sensitivity\n",
    "\n",
    "For fainter sources, lower the SNR threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823b10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original detection\n",
    "traces_default = detect_traces_cross_correlation(\n",
    "    calibrated_data,\n",
    "    expected_fwhm=4.0,\n",
    "    min_snr=3.0\n",
    ")\n",
    "\n",
    "# More sensitive detection for faint sources\n",
    "traces_sensitive = detect_traces_cross_correlation(\n",
    "    calibrated_data,\n",
    "    expected_fwhm=4.0,\n",
    "    min_snr=2.0  # Lower threshold\n",
    ")\n",
    "\n",
    "print(\"Trace Detection Comparison:\")\n",
    "print(f\"  Default (SNRâ‰¥3.0): {len(traces_default)} trace(s)\")\n",
    "print(f\"  Sensitive (SNRâ‰¥2.0): {len(traces_sensitive)} trace(s)\")\n",
    "print(f\"\\nNote: Lower SNR threshold may detect more traces but\")\n",
    "print(f\"increases false positive rate. Verify visually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeba81a3",
   "metadata": {},
   "source": [
    "### Modify Wavelength Polynomial Order\n",
    "\n",
    "Try different polynomial orders if automatic selection is suboptimal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different polynomial orders\n",
    "if len(matched_lines) >= 10:\n",
    "    orders_to_test = [3, 5, 7]\n",
    "    results = []\n",
    "    \n",
    "    for order in orders_to_test:\n",
    "        sol = fit_wavelength_solution(\n",
    "            matched_lines,\n",
    "            order_range=(order, order),  # Fixed order\n",
    "            sigma_clip=3.0\n",
    "        )\n",
    "        results.append({'order': order, 'rms': sol.rms_residual})\n",
    "    \n",
    "    print(\"Polynomial Order Comparison:\")\n",
    "    print(\"  Order | RMS Residual (Ã…)\")\n",
    "    print(\"  ------|------------------\")\n",
    "    for res in results:\n",
    "        print(f\"    {res['order']}   |   {res['rms']:.5f}\")\n",
    "    \n",
    "    best = min(results, key=lambda x: x['rms'])\n",
    "    print(f\"\\nBest order: {best['order']} (RMS = {best['rms']:.5f} Ã…)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c0c1b",
   "metadata": {},
   "source": [
    "## 8. Batch Processing\n",
    "\n",
    "Process multiple science frames efficiently using the pipeline runner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7fc07",
   "metadata": {},
   "source": [
    "### Use PipelineRunner for Automated Processing\n",
    "\n",
    "Process an entire night's observations with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79376f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('reduced_output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Initialize pipeline runner\n",
    "runner = PipelineRunner(\n",
    "    input_dir=data_dir,\n",
    "    output_dir=output_dir,\n",
    "    mode='batch',  # Auto-process all traces\n",
    "    max_traces=5\n",
    ")\n",
    "\n",
    "print(\"Pipeline Configuration:\")\n",
    "print(f\"  Input directory: {data_dir}\")\n",
    "print(f\"  Output directory: {output_dir}\")\n",
    "print(f\"  Mode: batch (automatic)\")\n",
    "print(f\"  Max traces per frame: 5\")\n",
    "\n",
    "# Run pipeline\n",
    "print(\"\\nRunning pipeline...\")\n",
    "try:\n",
    "    reduced_data_list = runner.run()\n",
    "    \n",
    "    print(f\"\\nâœ“ Pipeline completed successfully!\")\n",
    "    print(f\"\\nProcessed {len(reduced_data_list)} science frame(s):\")\n",
    "    \n",
    "    for i, reduced_data in enumerate(reduced_data_list, 1):\n",
    "        print(f\"\\n  Frame {i}: {reduced_data.source_frame.file_path.name}\")\n",
    "        print(f\"    Traces extracted: {len(reduced_data.spectra_1d)}\")\n",
    "        print(f\"    Overall grade: {reduced_data.quality_metrics.overall_grade}\")\n",
    "        print(f\"    Median SNR: {reduced_data.quality_metrics.median_snr:.2f}\")\n",
    "    \n",
    "    print(f\"\\nOutput products saved to: {output_dir}\")\n",
    "    print(\"  â€¢ calibrations/: Master bias, flat, arc solutions\")\n",
    "    print(\"  â€¢ reduced_2d/: Calibrated 2D spectra\")\n",
    "    print(\"  â€¢ spectra_1d/: Extracted 1D spectra (wavelength calibrated)\")\n",
    "    print(\"  â€¢ quality_reports/: Quality assessment reports\")\n",
    "    print(\"  â€¢ diagnostic_plots/: Diagnostic plots (2D, wavelength, profiles)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâœ— Pipeline error: {e}\")\n",
    "    print(\"\\nCommon issues:\")\n",
    "    print(\"  â€¢ Missing FITS files in input directory\")\n",
    "    print(\"  â€¢ Insufficient calibration frames (need â‰¥3 bias, â‰¥3 flat, â‰¥1 arc)\")\n",
    "    print(\"  â€¢ FITS header keywords missing (IMAGETYP, OBJECT, EXPTIME)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa3f48a",
   "metadata": {},
   "source": [
    "### Generate Summary Statistics\n",
    "\n",
    "Analyze quality metrics across all processed spectra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee64559",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'reduced_data_list' in locals() and reduced_data_list:\n",
    "    # Collect metrics from all spectra\n",
    "    all_snr = []\n",
    "    all_grades = []\n",
    "    \n",
    "    for reduced_data in reduced_data_list:\n",
    "        all_snr.append(reduced_data.quality_metrics.median_snr)\n",
    "        all_grades.append(reduced_data.quality_metrics.overall_grade)\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"Batch Processing Summary:\")\n",
    "    print(f\"  Total spectra extracted: {len(all_snr)}\")\n",
    "    print(f\"  Mean SNR: {np.mean(all_snr):.2f}\")\n",
    "    print(f\"  Median SNR: {np.median(all_snr):.2f}\")\n",
    "    print(f\"  SNR range: {np.min(all_snr):.2f} - {np.max(all_snr):.2f}\")\n",
    "    \n",
    "    # Grade distribution\n",
    "    from collections import Counter\n",
    "    grade_counts = Counter(all_grades)\n",
    "    print(f\"\\nGrade Distribution:\")\n",
    "    for grade in ['Excellent', 'Good', 'Fair', 'Poor']:\n",
    "        count = grade_counts.get(grade, 0)\n",
    "        pct = 100 * count / len(all_grades) if all_grades else 0\n",
    "        print(f\"  {grade}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Visualize SNR distribution\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.hist(all_snr, bins=20, edgecolor='black', alpha=0.7)\n",
    "    ax.axvline(np.median(all_snr), color='r', linestyle='--', \n",
    "              linewidth=2, label=f'Median SNR = {np.median(all_snr):.2f}')\n",
    "    ax.set_xlabel('Median SNR')\n",
    "    ax.set_ylabel('Number of Spectra')\n",
    "    ax.set_title('SNR Distribution Across All Extracted Spectra')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Run the batch processing cell above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f4390e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial demonstrated the complete pyKOSMOS spectroscopic reduction workflow:\n",
    "\n",
    "âœ… **Calibration**: Created master bias and flat frames with validation  \n",
    "âœ… **Wavelength Calibration**: Detected arc lines and fit wavelength solution (RMS <0.2Ã…)  \n",
    "âœ… **Extraction**: Detected traces and extracted 1D spectra with optimal weighting  \n",
    "âœ… **Quality Assessment**: Computed SNR and assigned quality grades  \n",
    "âœ… **Batch Processing**: Automated pipeline for multiple observations  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Interactive Mode**: Use `mode='interactive'` to visually select traces\n",
    "2. **Custom Parameters**: Tune detection thresholds for your specific observations\n",
    "3. **Flux Calibration**: Add standard star observations for absolute flux calibration\n",
    "4. **Documentation**: See `docs/` for complete API reference and user guides\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **GitHub**: [pykosmospp repository](https://github.com/gkhullar/pykosmospp)\n",
    "- **Documentation**: [Read the Docs](https://pykosmospp.readthedocs.io)\n",
    "- **Issues**: [Report bugs or request features](https://github.com/gkhullar/pykosmospp/issues)\n",
    "\n",
    "---\n",
    "\n",
    "*Tutorial created for pyKOSMOS v0.1.0 | December 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948e30f",
   "metadata": {},
   "source": [
    "## 9. Advanced Features\n",
    "\n",
    "### 9.1 Extraction Method Comparison\n",
    "\n",
    "pyKOSMOS++ supports multiple extraction methods. Let's compare optimal vs boxcar extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract using both optimal and boxcar methods\n",
    "from pykosmospp.extraction import extract_spectrum\n",
    "\n",
    "# Load a processed science frame\n",
    "science_file = output_dir / \"processed\" / \"science_001_processed.fits\"\n",
    "science_frame = ScienceFrame.from_fits(science_file)\n",
    "\n",
    "# Extract with optimal (Horne 1986) method\n",
    "spectrum_optimal = extract_spectrum(\n",
    "    science_frame.data,\n",
    "    science_frame.variance,\n",
    "    science_frame.trace,\n",
    "    method='optimal'\n",
    ")\n",
    "\n",
    "# Extract with boxcar method (10-pixel aperture)\n",
    "spectrum_boxcar = extract_spectrum(\n",
    "    science_frame.data,\n",
    "    science_frame.variance,\n",
    "    science_frame.trace,\n",
    "    method='boxcar',\n",
    "    aperture_width=10\n",
    ")\n",
    "\n",
    "# Compare signal-to-noise\n",
    "continuum_region = (spectrum_optimal.wavelength.value > 5500) & (spectrum_optimal.wavelength.value < 5600)\n",
    "snr_optimal = np.median(spectrum_optimal.flux[continuum_region] / np.sqrt(spectrum_optimal.uncertainty.array[continuum_region]**2))\n",
    "snr_boxcar = np.median(spectrum_boxcar.flux[continuum_region] / np.sqrt(spectrum_boxcar.uncertainty.array[continuum_region]**2))\n",
    "\n",
    "print(f\"SNR (5500-5600Ã…):\")\n",
    "print(f\"  Optimal extraction: {snr_optimal:.1f}\")\n",
    "print(f\"  Boxcar extraction:  {snr_boxcar:.1f}\")\n",
    "print(f\"  Improvement: {snr_optimal/snr_boxcar:.2f}x\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Full spectrum comparison\n",
    "ax1.plot(spectrum_optimal.wavelength, spectrum_optimal.flux, label='Optimal', alpha=0.8)\n",
    "ax1.plot(spectrum_boxcar.wavelength, spectrum_boxcar.flux, label='Boxcar', alpha=0.8)\n",
    "ax1.set_ylabel('Flux')\n",
    "ax1.set_title('Extraction Method Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom on continuum region\n",
    "zoom = (spectrum_optimal.wavelength.value > 5500) & (spectrum_optimal.wavelength.value < 5600)\n",
    "ax2.plot(spectrum_optimal.wavelength[zoom], spectrum_optimal.flux[zoom], label='Optimal', alpha=0.8)\n",
    "ax2.plot(spectrum_boxcar.wavelength[zoom], spectrum_boxcar.flux[zoom], label='Boxcar', alpha=0.8)\n",
    "ax2.set_xlabel('Wavelength (Ã…)')\n",
    "ax2.set_ylabel('Flux')\n",
    "ax2.set_title('Continuum Region (5500-5600Ã…)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Optimal extraction typically provides 10-30% better SNR than boxcar,\")\n",
    "print(\"   especially for faint objects or when PSF varies with wavelength.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9989500d",
   "metadata": {},
   "source": [
    "### 9.2 Cosmic Ray Detection and Visualization\n",
    "\n",
    "Cosmic rays are a common source of contamination in astronomical spectra. pyKOSMOS++ includes robust cosmic ray detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936873b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect cosmic rays in a science frame\n",
    "from pykosmospp.cosmic_rays import detect_cosmic_rays\n",
    "\n",
    "# Load raw science frame (before CR rejection)\n",
    "raw_science = CCDData.read(data_dir / \"science\" / \"science_001.fits\", unit='adu')\n",
    "\n",
    "# Detect cosmic rays\n",
    "cr_mask = detect_cosmic_rays(raw_science, sigclip=5.0, sigfrac=0.3, objlim=5.0)\n",
    "\n",
    "print(f\"Detected {cr_mask.sum()} cosmic ray pixels ({100*cr_mask.sum()/cr_mask.size:.3f}% of frame)\")\n",
    "\n",
    "# Visualize cosmic rays\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Original data\n",
    "im0 = axes[0].imshow(raw_science.data, origin='lower', vmin=3000, vmax=5000, cmap='gray')\n",
    "axes[0].set_title('Raw Science Frame')\n",
    "axes[0].set_xlabel('Spectral Pixel')\n",
    "axes[0].set_ylabel('Spatial Pixel')\n",
    "plt.colorbar(im0, ax=axes[0], label='ADU')\n",
    "\n",
    "# Cosmic ray mask\n",
    "im1 = axes[1].imshow(cr_mask, origin='lower', cmap='Reds', alpha=0.8)\n",
    "axes[1].set_title(f'Cosmic Ray Mask ({cr_mask.sum()} pixels)')\n",
    "axes[1].set_xlabel('Spectral Pixel')\n",
    "axes[1].set_ylabel('Spatial Pixel')\n",
    "plt.colorbar(im1, ax=axes[1], label='CR Flag')\n",
    "\n",
    "# Overlay\n",
    "axes[2].imshow(raw_science.data, origin='lower', vmin=3000, vmax=5000, cmap='gray')\n",
    "axes[2].contour(cr_mask, levels=[0.5], colors='red', linewidths=0.5, alpha=0.7)\n",
    "axes[2].set_title('Data with CR Overlay')\n",
    "axes[2].set_xlabel('Spectral Pixel')\n",
    "axes[2].set_ylabel('Spatial Pixel')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show a zoomed region with CR\n",
    "if cr_mask.sum() > 0:\n",
    "    # Find a region with cosmic rays\n",
    "    cr_locs = np.where(cr_mask)\n",
    "    idx = len(cr_locs[0]) // 2  # Pick middle CR\n",
    "    y_cr, x_cr = cr_locs[0][idx], cr_locs[1][idx]\n",
    "    \n",
    "    # Zoom window\n",
    "    y_slice = slice(max(0, y_cr-20), min(raw_science.shape[0], y_cr+20))\n",
    "    x_slice = slice(max(0, x_cr-20), min(raw_science.shape[1], x_cr+20))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Zoomed data\n",
    "    im1 = ax1.imshow(raw_science.data[y_slice, x_slice], origin='lower', cmap='gray')\n",
    "    ax1.axhline(y_cr - y_slice.start, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.axvline(x_cr - x_slice.start, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.set_title(f'Zoomed View (CR at pixel [{y_cr}, {x_cr}])')\n",
    "    ax1.set_xlabel('Spectral Pixel')\n",
    "    ax1.set_ylabel('Spatial Pixel')\n",
    "    plt.colorbar(im1, ax=ax1, label='ADU')\n",
    "    \n",
    "    # Zoomed mask\n",
    "    im2 = ax2.imshow(cr_mask[y_slice, x_slice], origin='lower', cmap='Reds')\n",
    "    ax2.set_title('Cosmic Ray Mask (Zoomed)')\n",
    "    ax2.set_xlabel('Spectral Pixel')\n",
    "    ax2.set_ylabel('Spatial Pixel')\n",
    "    plt.colorbar(im2, ax=ax2, label='CR Flag')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nâœ¨ Cosmic rays are automatically rejected during reduction.\")\n",
    "print(\"   Detection parameters can be tuned in the configuration file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04ce06",
   "metadata": {},
   "source": [
    "### 9.3 Spectral and Spatial Binning\n",
    "\n",
    "Binning can improve signal-to-noise for faint objects. pyKOSMOS++ supports both spatial and spectral binning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spatial binning example\n",
    "from pykosmospp.binning import bin_spatial, bin_spectral\n",
    "\n",
    "# Load a processed 2D spectrum\n",
    "science_2d = CCDData.read(output_dir / \"processed\" / \"science_001_processed.fits\", unit='adu')\n",
    "\n",
    "# Apply 2x spatial binning (combine pixels along spatial axis)\n",
    "binned_data, binned_variance = bin_spatial(\n",
    "    science_2d.data,\n",
    "    science_2d.uncertainty.array**2 if science_2d.uncertainty else None,\n",
    "    bin_factor=2\n",
    ")\n",
    "\n",
    "print(f\"Original shape: {science_2d.data.shape}\")\n",
    "print(f\"Binned shape:   {binned_data.shape}\")\n",
    "print(f\"SNR improvement: ~{np.sqrt(2):.2f}x (for 2x binning)\")\n",
    "\n",
    "# Visualize spatial binning effect\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original\n",
    "im0 = axes[0].imshow(science_2d.data, origin='lower', vmin=3000, vmax=5000, cmap='gray', aspect='auto')\n",
    "axes[0].set_title('Original 2D Spectrum')\n",
    "axes[0].set_xlabel('Spectral Pixel')\n",
    "axes[0].set_ylabel('Spatial Pixel')\n",
    "plt.colorbar(im0, ax=axes[0], label='ADU')\n",
    "\n",
    "# Spatially binned\n",
    "im1 = axes[1].imshow(binned_data, origin='lower', vmin=3000, vmax=5000, cmap='gray', aspect='auto')\n",
    "axes[1].set_title('Spatially Binned (2x)')\n",
    "axes[1].set_xlabel('Spectral Pixel')\n",
    "axes[1].set_ylabel('Spatial Pixel (binned)')\n",
    "plt.colorbar(im1, ax=axes[1], label='ADU')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Spectral binning example\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Spectral binning - smooth spectrum to lower resolution\n",
    "spectrum = spectrum_optimal  # From previous section\n",
    "\n",
    "# Bin to 5Ã… resolution\n",
    "binned_spectrum = bin_spectral(spectrum, bin_width_angstrom=5.0)\n",
    "\n",
    "print(f\"Original spectrum: {len(spectrum.wavelength)} pixels\")\n",
    "print(f\"Binned spectrum:   {len(binned_spectrum.wavelength)} pixels\")\n",
    "\n",
    "# Compare spectra\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Full spectrum\n",
    "ax1.plot(spectrum.wavelength, spectrum.flux, alpha=0.5, label='Original', linewidth=0.5)\n",
    "ax1.plot(binned_spectrum.wavelength, binned_spectrum.flux, label='Binned (5Ã…)', linewidth=2)\n",
    "ax1.set_ylabel('Flux')\n",
    "ax1.set_title('Spectral Binning Comparison')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Zoom on emission line\n",
    "zoom = (spectrum.wavelength.value > 6550) & (spectrum.wavelength.value < 6575)\n",
    "zoom_binned = (binned_spectrum.wavelength.value > 6550) & (binned_spectrum.wavelength.value < 6575)\n",
    "ax2.plot(spectrum.wavelength[zoom], spectrum.flux[zoom], alpha=0.5, label='Original', linewidth=0.5)\n",
    "ax2.plot(binned_spectrum.wavelength[zoom_binned], binned_spectrum.flux[zoom_binned], \n",
    "         'o-', label='Binned (5Ã…)', markersize=4)\n",
    "ax2.set_xlabel('Wavelength (Ã…)')\n",
    "ax2.set_ylabel('Flux')\n",
    "ax2.set_title('Zoom on HÎ± Region')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ Spatial binning: Improves SNR at the cost of spatial resolution\")\n",
    "print(\"   Spectral binning: Improves SNR at the cost of spectral resolution\")\n",
    "print(\"   Use binning when SNR is more critical than resolution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6db552",
   "metadata": {},
   "source": [
    "### 9.4 Flux Calibration\n",
    "\n",
    "pyKOSMOS++ includes tools for atmospheric extinction correction and flux calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49698c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atmospheric extinction correction\n",
    "from pykosmospp.flux_calibration import apply_extinction_correction\n",
    "\n",
    "# Get airmass from header\n",
    "airmass = science_frame.header.get('AIRMASS', 1.2)\n",
    "print(f\"Observation airmass: {airmass:.2f}\")\n",
    "\n",
    "# Apply extinction correction\n",
    "spectrum_corrected = apply_extinction_correction(spectrum_optimal, airmass=airmass)\n",
    "\n",
    "# Compare before/after\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Full spectrum comparison\n",
    "ax1.plot(spectrum_optimal.wavelength, spectrum_optimal.flux, label='Uncorrected', alpha=0.7)\n",
    "ax1.plot(spectrum_corrected.wavelength, spectrum_corrected.flux, label='Extinction Corrected', alpha=0.7)\n",
    "ax1.set_ylabel('Flux')\n",
    "ax1.set_title('Atmospheric Extinction Correction')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Show correction factor vs wavelength\n",
    "correction_factor = spectrum_corrected.flux / spectrum_optimal.flux\n",
    "ax2.plot(spectrum_optimal.wavelength, correction_factor)\n",
    "ax2.axhline(1.0, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Wavelength (Ã…)')\n",
    "ax2.set_ylabel('Correction Factor')\n",
    "ax2.set_title('Extinction Correction Factor')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Extinction correction factors:\")\n",
    "print(f\"   Blue (4000Ã…):  {correction_factor[np.argmin(np.abs(spectrum_optimal.wavelength.value - 4000))]:.3f}x\")\n",
    "print(f\"   Green (5500Ã…): {correction_factor[np.argmin(np.abs(spectrum_optimal.wavelength.value - 5500))]:.3f}x\")\n",
    "print(f\"   Red (7000Ã…):   {correction_factor[np.argmin(np.abs(spectrum_optimal.wavelength.value - 7000))]:.3f}x\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Extinction correction:\")\n",
    "print(\"   - Corrects for wavelength-dependent atmospheric absorption\")\n",
    "print(\"   - Blue light is more strongly absorbed than red\")\n",
    "print(\"   - Effect increases with airmass (zenith distance)\")\n",
    "print(\"   - Essential for accurate relative flux measurements\")\n",
    "\n",
    "print(\"\\nðŸ“ For absolute flux calibration:\")\n",
    "print(\"   1. Observe spectrophotometric standard star at similar airmass\")\n",
    "print(\"   2. Compute sensitivity function from standard\")\n",
    "print(\"   3. Apply sensitivity correction to science spectra\")\n",
    "print(\"   4. See documentation for compute_sensitivity_function() and apply_sensitivity_correction()\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
